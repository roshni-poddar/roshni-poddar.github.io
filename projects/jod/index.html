<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jod | Roshni  Poddar</title>
    <meta name="author" content="Roshni  Poddar">
    <meta name="description" content="a videoconferencing platform for mixed hearing groups">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://roshni-poddar.github.io/projects/jod/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Roshni </span>Poddar</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <article>
            <h1 id="jod-a-videoconferencing-platform-for-mixed-hearing-groups">
<i>Jod</i>: A Videoconferencing Platform for Mixed Hearing Groups</h1>
<p><i>Jod</i>’s features were iteratively designed using a combination of findings from prior work examining accessibility barriers in current videoconferencing platforms and feedback received from the participants in the first user study session.</p>

<h2 id="prior-work">Prior work</h2>
<p>Three primary challenges faced by Deaf and Hard of Hearing (DHH) individuals when using existing videoconferencing platforms:</p>

<ol>
  <li>
    <p><strong>Limited Layout Customization</strong>: Current platforms offer minimal options for customizing layouts and often automatically adjust and distribute video thumbnails, making visual communication difficult.</p>
  </li>
  <li>
    <p><strong>Communication Difficulties</strong>: DHH individuals often struggle to capture the attention of others, and in mixed hearing videoconferencing scenarios, both hearing and DHH participants face challenges in remembering appropriate communication accommodations.</p>
  </li>
  <li>
    <p><strong>Audio-Centric Design</strong>: Existing platforms predominantly prioritize audio, and do not highlight signing individuals’ video tile.</p>
  </li>
</ol>

<h2 id="jod-features">
<i>Jod</i> Features</h2>
<ol>
  <li>
    <p><strong>Customizable Visual Layout</strong>: Users can easily resize, add, remove, and reposition video tiles, captions, and screen share windows, enabling them to reorganize their visual layout to suit their personal preferences. Refer to Figure <a href="#videotile">2a</a>.</p>
  </li>
  <li>
    <p><strong>Preset Feedback Messages</strong>: Users can send predefined feedback messages like <i>“Please look at me”</i>, <i>“Please keep your upper body visible”</i>, <i>“Please turn on some lights”</i>, <i>“Please speak slower”</i>, <i>“Please use easier language”</i>, and <i>“Please repeat what you said”</i> by hovering over a participant’s video tile, promoting effective communication. Refer to Figure <a href="#videotile">2a</a>.</p>
  </li>
  <li>
    <p><strong>Active Signer Identification</strong>: <i>Jod</i> uses a Wizard of Oz method to identify the active signer.</p>
  </li>
  <li>
    <p><strong>Accessibility Indicators</strong>: Users can specify their participant type (Deaf, Hearing, or Interpreter) upon joining a call, denoted by colors, icons, and labels in the user interface.</p>
  </li>
  <li>
    <p><strong>Enhanced Transcription</strong>: <i>Jod</i> improves audio transcriptions and captions by including preset feedback messages, emoji reactions, and indicating when a DHH user begins or stops signing. Transcriptions also display the accessibility indicator of each participant. Refer to Figure <a href="#transcription">2b</a>.</p>
  </li>
  <li>
    <p><strong>Gesture Recognition</strong>: To enhance feedback options while muted, users can use four emoji-based gestures: clap, hand raise, okay, and thumbs-up, which can be enabled by clicking on “Enable Gestures” in the gesture control bar. Refer to Figure <a href="#ui_interface">1</a>.</p>
  </li>
</ol>

<p>Here are some screenshots of Jod:</p>

<div class="row">

<div class="col-sm mt-3 mt-md-0 d-flex justify-content-center">

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img id="ui_interface" src="/assets/img/UI-Interface.png" class="custom-img rounded z-depth-1" width="auto" height="350 px" alt="A full-screen screenshot of the user interface of Jod with six participants (3 DHH, 1 ISL interpreter, 2 hearing individuals) on a simulated video call. The background is dark, and the text is white. Three participants (Priya P, Interpreter Indira I, and Neel N) have their videos turned on, and their faces are blurred for anonymity. The top panel contains icons for the gesture and call controls. The right panel has three tabs: People, Chat, and Transcription. The people tab is selected and lists the six participants' names vertically: Priya P, Neel N, Indira I, Meera M, Anna A, and Shreya S. There is a mike and video icon to the arranged horizontally to the right and an accessibility indicator icon to the left of each participant name. Shreya S's video tile has been removed, so there is an Add button to the right of her video icon in the People tab. The remaining visual space on the left is used for rendering video tiles and a captions box centered under them. The interpreter Indira's video tile is the largest and in the center. To the left of it are two equally sized video tiles for DHH participants -  Priya vertically followed by Meera. On the right of the interpreter are two equally sized video tiles for hearing participants -  Neel N vertically followed by Anna A." title="question interface" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>
</div>
<div class="caption">
Figure 1: User Interface of <i>Jod</i> with six participants on a simulated video call. 6 participants comprise 3 DHH, 2 Hearing, and 1 Interpreter.
</div>

<div class="row d-flex justify-content-center">

<div class="col-sm-5 mt-3 mt-md-0 " style="margin-right: 40px;">

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img id="videotile" src="/assets/img/Video-Tile-Hover.png" class="custom-img rounded z-depth-1" width="auto" height="160 px" alt="Jod's video tile hover state with labeled icon buttons and corners using which a person can resize the video tile. The video tile is of the simulated participant Neel N. In the top-left corner, there are three icons labeled (a) Lock/Unlock video Tile, (b) Remove Video tile, and (c) Turn Neel N's video feed on or off. In the bottom-right corner are 6 icons, one for sending each preset message. From left to right, they are labeled as: (e) Request Neel N to look at you, (f) Request Neel N to keep their upper body visible, (g) Request Neel N to turn on lights, (h) Request Neel N to speak slowly, (i) Request Neel N to use easier language, and (j) Request Neel N to repeat what they said." title="Video Tile Hover State" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="caption">(a) Video Tile Hover State</figcaption>

</figure>


</div>

<div class="col-sm-3 mt-3 mt-md-0">

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img id="transcription" src="/assets/img/Enhanced-Transcription.png" class="custom-img rounded z-depth-1" width="auto" height="160 px" alt="A zoomed-in screenshot of the participant Priya P's transcription panel showing a snippet of conversation between Priya, Indira, and Neel. The UI background is dark, and the text is white. Three are three accessibility indicator icons to the left of each participant's name: a green-colored DHH icon for Priya, a red-colored icon for interpreter Indira, and a blue-colored hearing icon for Neel. The user interface components are labeled to show (a) when Priya P started signing, (b) a sample ASR output 'We are going to game.', a preset feedback message 'Please speak slower' which Priya sent to Neel, (c) an okay emoji reaction from Neel, and (d) when Priya P stopped signing." title="Transcriptions Panel" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="caption">(b) Transcription Panel</figcaption>

</figure>


</div>

</div>

<div class="caption">
Figure 2: Jod’s System Features: Customizable Visual Layout, Preset Feedback Messages, and Enhanced Transcriptions
</div>

<h2 id="user-study">User Study</h2>
<p>Using Jod, we conducted <strong>six mixed hearing group sessions</strong>, with four held in person and two conducted remotely, with a total of 34 participants. This group comprised <strong>18 d/Deaf or hard of hearing participants, 10 hearing participants, and six sign language interpreters</strong>.</p>

<p>Each study session lasted approximately <strong>2.5 hours</strong> and included three DHH signers, one or two interpreters, two hearing individuals, and two hearing researchers. Our sessions had the following structure:</p>
<ul>
<li>10-minute <i>Jod</i> tutorial</li>
<li>30-minute task-based explorations to acquaint participants with Jod's features</li>
<li>Unstructured conversations on topics like food and festivals</li>
<li>Modified version of the charades game to promote direct communication</li>
<li>Presentation round incorporating screen sharing.</li>
</ul>

<p>The study culminated in a <strong>focus group discussion</strong> aimed at comprehending participants’ general perceptions of Jod, collecting detailed feedback on its key features, and gathering suggestions for potential future enhancements.</p>

<p>The study protocol maintained consistency across both remote and in-person sessions. During remote sessions, we conducted initial introductions, <i>Jod</i> onboarding, and focus group discussions on Zoom, while all other study-related activities took place on Jod.</p>

<h3 id="some-findings">Some Findings</h3>
<ol>
<li> DHH participants chose to allocate significant visual space to the interpreter, while some opted to keep all participants on the screen, minimizing the visual presence of hearing participants. Others even removed hearing participants from their view. However, manually resizing video tiles proved time-consuming. </li>

<li> Interpreters adjusted the size of DHH participants' and researchers' video tiles, making them larger than others. </li>

<li> A valuable "started signing" message in captions and transcriptions helped interpreters and hearing participants identify signers. DHH participants used transcriptions to follow conversations and captions to verify interpretations or continue conversations when the interpreter wasn't available. </li>

<li> Concerning preset messages, a DHH participant appreciated capturing the attention of the interpreter with ease. A hearing participant directly conversed with a DHH participant without the interpreter. However, participants noted two issues: notification messages required manual dismissal, and there was no acknowledgment of receipt. </li>
</ol>

<h3 id="design-recommendations">Design Recommendations</h3>
<p>These are some of the design recommendations from the paper:</p>
<ol>
  <li>Providing quick layout options like one-click actions for adding/removing video tiles based on hearing ability, a revert button for layout changes, and dynamic templates to suit various conversation needs.</li>
  <li>Making preset message notifications less obstructive and allowing recipients to acknowledge them. It is also important to consider priority of the notification based on the communication context.</li>
  <li>Videoconferencing platforms may improve user profiles by enabling users to add sign names through short self-recorded videos.</li>
</ol>

<h3 id="insights-from-in-person-sessions">Insights from In-Person Sessions</h3>
<p>The in-person study sessions, especially the charades game, played a crucial role in fostering camaraderie among participants. It helped them get more comfortable with each other and encouraged direct communication. The focus group discussions allowed for productive conversations between hearing and DHH participants and provided valuable feedback on feature suggestions. I believe that the these sessions proved more effective than individual interviews would have been.</p>

<hr>

<p>Please find the full paper - <a href="/assets/pdf/assets23_5.pdf">Jod Paper</a></p>

<p>We’d like to express our sincere thanks to the <a href="https://winvinayafoundation.org/" rel="external nofollow noopener" target="_blank">WinVinaya foundation</a> for their invaluable support in this study. I encourage you to support their mission of providing employment opportunities for people with disabilities. On a personal note, it was a great experience to collaborate with <a href="https://anantmittal.github.io/#/" rel="external nofollow noopener" target="_blank">Anant Mittal</a> and <a href="https://gupta-meghna64.github.io/" rel="external nofollow noopener" target="_blank">Meghna Gupta</a> for the first time on this research. I learned a lot from them and was truly inspired by their dedication, hard work, and kindness.</p>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Roshni  Poddar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
